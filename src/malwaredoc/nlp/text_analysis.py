"""Methods to summarize text."""
from langchain import LLMChain, PromptTemplate
from langchain.chains import (
    AnalyzeDocumentChain,
    MapReduceDocumentsChain,
    ReduceDocumentsChain,
    StuffDocumentsChain,
)
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.llms.base import LLM
from langchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter
from llama_index import (
    Document,
    LangchainEmbedding,
    LLMPredictor,
    ServiceContext,
    VectorStoreIndex,
)

from malwaredoc.nlp.code.models import FlanT5Base


def _map_reduce(
    text: str,
    reduce_llm_chain: LLMChain,
    document_prompt: PromptTemplate,
    document_variable_name: str,
    llm_chain: LLMChain,
    text_splitter: TextSplitter,
) -> str:
    combine_documents_chain = StuffDocumentsChain(
        llm_chain=reduce_llm_chain,
        document_prompt=document_prompt,
        document_variable_name=document_variable_name,
    )
    reduce_documents_chain = ReduceDocumentsChain(
        combine_documents_chain=combine_documents_chain,
    )
    summary_chain = MapReduceDocumentsChain(
        llm_chain=llm_chain,
        reduce_documents_chain=reduce_documents_chain,
    )
    summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain, text_splitter=text_splitter)
    if len(text_splitter.split_text(text)) == 1:
        return llm_chain.run(text)
    return summarize_document_chain.run(text)


def sentiment_text(text: str, llm=FlanT5Base()) -> str:
    """
    Get text sentiment.

    This automatically applies map_reduce if
    the text is longer than given sequence length.
    Args:
        text: text to analyze.
        llm: llm to use.

    Returns:

    """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000, chunk_overlap=400, length_function=len, keep_separator=True
    )
    document_prompt = PromptTemplate(input_variables=["page_content"], template="{page_content}")
    document_variable_name = "context"
    prompt = PromptTemplate.from_template("Summarize text: {context}")
    llm_chain = LLMChain(llm=llm, prompt=prompt)
    reduce_prompt = PromptTemplate.from_template("What is the sentiment of: {context}")
    reduce_llm_chain = LLMChain(llm=llm, prompt=reduce_prompt)
    return _map_reduce(
        text=text,
        reduce_llm_chain=reduce_llm_chain,
        document_prompt=document_prompt,
        document_variable_name=document_variable_name,
        llm_chain=llm_chain,
        text_splitter=text_splitter,
    )


def summarize_text(text: str, llm: LLM = FlanT5Base()) -> str:
    """
    Summarize text using model.

    Summarizes text using FlanT5Large with
    Args:
        llm: llm model to use.
        text: text to summarize.

    Returns:
        string with text summary.
    """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000, chunk_overlap=250, length_function=len, keep_separator=True
    )

    document_prompt = PromptTemplate(input_variables=["page_content"], template="{page_content}")
    document_variable_name = "context"
    prompt = PromptTemplate.from_template("Summarize text: {context}")
    llm_chain = LLMChain(llm=llm, prompt=prompt)
    reduce_prompt = PromptTemplate.from_template("Summarize text: {context}")
    reduce_llm_chain = LLMChain(llm=llm, prompt=reduce_prompt)
    return _map_reduce(
        text=text,
        reduce_llm_chain=reduce_llm_chain,
        document_prompt=document_prompt,
        document_variable_name=document_variable_name,
        llm_chain=llm_chain,
        text_splitter=text_splitter,
    )


def _summarize_text_with_text_as_query_engine(
    text: str, embedding_model_name: str = "distiluse-base-multilingual-cased-v2"
) -> str:
    model = FlanT5Base()
    embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=embedding_model_name))
    predictor = LLMPredictor(llm=model)

    service_context = ServiceContext.from_defaults(embed_model=embed_model, llm_predictor=predictor)

    documents = [Document(text=text)]  # Todo: Might need to use prompt helper
    index = VectorStoreIndex.from_documents(documents=documents, service_context=service_context)
    query_engine = index.as_query_engine()
    response = query_engine.query("Summarize this text in a couple of sentences.")
    return response.response
