"""Sequential data extact from documents."""


import typing
from abc import ABC, abstractmethod
from enum import Enum
from pathlib import Path
from typing import Callable, List, TypeVar, Union

from filetype.types import Type
from filetype.types.archive import Pdf, Rar, Rtf, Zip
from filetype.types.document import Doc, Docx, Ppt, Pptx, Xls, Xlsx

from malwaredoc.data.base import Base
from malwaredoc.data.data import (
    EditableFileAnalysis,
    FileAnalysis,
    OfficeFileAnalysis,
    PdfFileAnalysis,
    RarFileAnalysis,
    RtfFileAnalysis,
    WordFileAnalysis,
    XlsxFileAnalysis,
    ZipFileAnalysis,
)
from malwaredoc.extract.metadata import (
    extract_exif_features,
    extract_magika_features,
    get_file_type,
    get_pdf_metadata,
    get_rar_metadata,
    get_zip_metadata,
)
from malwaredoc.extract.office.common import (
    get_dde_streams,
    get_external_relationship,
    get_indicators,
    get_mraptor_analysis,
    get_text_content,
    get_vba_code,
    get_vba_code_analysis,
    has_vba_code,
)
from malwaredoc.extract.office.word import get_paragraphs
from malwaredoc.extract.office.xlsx import extract_text_xlsx
from malwaredoc.extract.pdf import (
    extract_attachments_from_pdf,
    extract_images_from_pdf,
    extract_text_from_pdf,
)
from malwaredoc.extract.rar import unrar_file
from malwaredoc.extract.rtf import analyze_rtf, extract_raw_rtf, extract_text_rtf
from malwaredoc.extract.zip import unzip_with_7z
from malwaredoc.util.filesystem import (
    TempFolderProvider,
    delete_all_files_and_sub_folders,
    get_all_files_in_dir_and_subdirs,
)

T = TypeVar("T", bound=Base)
V = TypeVar("V", bound=Base)


def _extend_model(original: V, target: typing.Type[T], **kwargs) -> T:
    """Extend a Model with additional information.

    Args:
        original (Base): original model.
        target (typing.Type[Base]): type of new model.

    Returns:
        Base: target model with included kwargs.
    """
    d = original.model_dump()
    d.update(kwargs)
    return target(**d)


class Pipeline(ABC):
    def __init__(self, depth: int = 1, max_depth: int = 10) -> None:
        super().__init__()
        self._depth = depth
        self._max_depth = max_depth

    @abstractmethod
    def process_file(self, path: Path) -> Base:
        """Process a file and extract relevant information.

        Args:
            path (Path): path to file.

        Returns:
            Base: extracted information.
        """


class UnreadableFilePipeline(Pipeline):
    """Does not do anything to the file."""

    def process_file(self, path: Path) -> Base:
        return FileAnalysis(
            name=path.name,
            absolute_path=str(path.resolve()),
            # exif_metadata=extract_exif_features(path),
            magika_meta=extract_magika_features(path),
            type_data=None,
            text_extract=None,
        )


class FilePipeline(Pipeline):
    """Analyze general file."""

    def process_file(self, path: Path) -> FileAnalysis:
        name = path.name
        absolute_path = str(path.resolve())
        type_data = get_file_type(path)
        text_extract = get_text_content(path=path, extension=type_data.extension_filetype)
       
        return FileAnalysis(
            name=name,
            absolute_path=absolute_path,
            # exif_metadata=extract_exif_features(path),
            type_data=type_data,
            text_extract=text_extract,
            magika_meta = extract_magika_features(path)
        )


class EditableFilePipeline(FilePipeline):
    """Analyze editables files."""

    def process_file(self, path: Path) -> EditableFileAnalysis:
        file_analysis = super().process_file(path)
        indicators = get_indicators(path)
        return _extend_model(file_analysis, EditableFileAnalysis, indicators=indicators)


class PDFPipeline(FilePipeline):
    """Analyzes pdf files."""

    def process_file(self, path: Path) -> PdfFileAnalysis:
        file_analysis = super().process_file(path)
        pdf_metadata = get_pdf_metadata(path)
        if not pdf_metadata or pdf_metadata.is_encrypted:
            attachments = None
            image_data = None
            text = None
        else:
            attachments = extract_attachments_from_pdf(path)
            image_data = extract_images_from_pdf(path)
            text = extract_text_from_pdf(path)
        return _extend_model(
            file_analysis,
            PdfFileAnalysis,
            pdf_metadata=pdf_metadata,
            attachments=attachments,
            image_data=image_data,
            text=text,
        )


class OfficePipeline(EditableFilePipeline):
    """Analyzes office files."""

    def process_file(self, path: Path) -> OfficeFileAnalysis:
        file_analysis = super().process_file(path)
        has_vba = has_vba_code(path)
        vba_code = get_vba_code(path)
        vba_analysis = get_vba_code_analysis(path)
        mraptor_analysis = get_mraptor_analysis(path)
        exif_metadata=extract_exif_features(path)
        try:
            zip_metadata = get_zip_metadata(path)
        except Exception:
            zip_metadata = None
            print("Failed to read zip metadata from office file.")
        return _extend_model(
            file_analysis,
            OfficeFileAnalysis,
            has_vba_code=has_vba,
            vba_code=vba_code,
            vba_analysis=vba_analysis,
            mraptor_analysis=mraptor_analysis,
            zip_metadata=zip_metadata,
            exif_metadata=exif_metadata,
            external_relationships=get_external_relationship(path),
            dde_stream=get_dde_streams(path)
        )


class WordFilePipeline(OfficePipeline):
    """Analyze word files."""

    def process_file(self, path: Path) -> OfficeFileAnalysis:
        file_analysis = super().process_file(path)
        paragraphs = get_paragraphs(path)
        return _extend_model(file_analysis, WordFileAnalysis, paragraphs=paragraphs)


class XlsxFilePipeline(OfficePipeline):
    """Analyze word files."""

    def process_file(self, path: Path) -> XlsxFileAnalysis:
        file_analysis = super().process_file(path)
        xlsx_text = extract_text_xlsx(path)
        return _extend_model(file_analysis, XlsxFileAnalysis, xlsx_text=xlsx_text)


class RtfPipeline(FilePipeline):
    """Analyzes rtf files."""

    def process_file(self, path: Path) -> RtfFileAnalysis:
        file_analysis = super().process_file(path)
        rtf_obj_analysis = analyze_rtf(path)
        rtf_text = extract_text_rtf(path)
        rtf_raw = extract_raw_rtf(path)
        return _extend_model(
            file_analysis, RtfFileAnalysis, rtf_obj_analysis=rtf_obj_analysis, rtf_text=rtf_text, rtf_raw=rtf_raw
        )


class ArchivePipeline(FilePipeline):
    """Analyze archives."""

    _temp_folder_provider: TempFolderProvider = TempFolderProvider(Path("./temp"))

    def __init__(self, depth: int, max_depth: int = 10) -> None:
        super().__init__(depth=depth, max_depth=max_depth)

    def _analyze_unpacked_files(
        self, path: Path, unpack_method: Callable[[Path, Path], None]
    ) -> List[
        Union[
            FileAnalysis,
            PdfFileAnalysis,
            OfficeFileAnalysis,
            RtfFileAnalysis,
            ZipFileAnalysis,
            RarFileAnalysis,
            WordFileAnalysis,
            XlsxFileAnalysis,
        ]
    ]:
        """Unpack and analyze files in archive.

        Args:
            path (Path): path to archive.
            unpack_method (Callable[[Path, Path], None]): method use to unpack archive.

        Returns:
            List: analysis of files.
        """

        temp_path, temp_number = self._temp_folder_provider.reserve_folder()
        try:
            print(f"Unpacking archive to: {temp_path}")
            unpack_method(path, temp_path)
            unziped_files = get_all_files_in_dir_and_subdirs(temp_path)
            pipeline = FeatureExtractionPipeline(depth=self._depth + 1, max_depth=self._max_depth)
            print("Analyzing files...")
            results = []
            for file_path in unziped_files:
                try:
                    result = pipeline.process_file(file_path)
                    results.append(result)
                except Exception as e:
                    print(f"Failed processing file inside archive: {file_path}, due to following exception: \n{str(e)}")
                    continue
        except Exception as e:
            print(f"Failed pipeline failed when processing archive contents...{str(e)}")
            results = []
        finally:
            print(f"Deleting files in: {temp_path}")
            delete_all_files_and_sub_folders(temp_path)
            self._temp_folder_provider.release_folder(temp_number)
        return results


class ZipPipeline(ArchivePipeline):
    """Analyzes Zip files and their contents"""

    def process_file(self, path: Path) -> ZipFileAnalysis:
        file_analysis = super().process_file(path)
        zip_metadata = get_zip_metadata(path)
        if self._depth > self._max_depth:
            print(f"Max recursion depth reached for Zip archives: {self._depth} > {self._max_depth}")
            return _extend_model(file_analysis, ZipFileAnalysis, zip_metadata=zip_metadata, files=[])
        files = self._analyze_unpacked_files(path=path, unpack_method=unzip_with_7z)
        return _extend_model(file_analysis, ZipFileAnalysis, zip_metadata=zip_metadata, files=files)


class RarPipeline(ArchivePipeline):
    """Analyzes Rar files and their contents"""

    def process_file(self, path: Path) -> RarFileAnalysis:
        file_analysis = super().process_file(path)
        rar_metadata = get_rar_metadata(path)
        if self._depth > self._max_depth:
            print(f"Max recursion depth reached for Rar archives: {self._depth} > {self._max_depth}")
            return _extend_model(file_analysis, RarFileAnalysis, rar_metadata=rar_metadata, files=[])
        files = self._analyze_unpacked_files(path=path, unpack_method=unrar_file)
        return _extend_model(file_analysis, RarFileAnalysis, rar_metadata=rar_metadata, files=files)


class PipelineType(Enum):
    UNKNOWN = FilePipeline
    RTF = RtfPipeline
    WORD = WordFilePipeline
    XLSX = XlsxFilePipeline
    OFFICE = OfficePipeline
    ZIP = ZipPipeline
    RAR = RarPipeline
    PDF = PDFPipeline
    NOT_READABLE = UnreadableFilePipeline


_FILE_TYPE_MAPPING: dict[PipelineType, List[typing.Any]] = {
    PipelineType.RAR: [Rar],
    PipelineType.RTF: [Rtf],
    PipelineType.PDF: [Pdf],
    PipelineType.WORD: [Docx],  # cannot handle doc files.
    PipelineType.XLSX: [Xlsx],
    PipelineType.OFFICE: [Ppt, Pptx, Xls, Doc],
    PipelineType.ZIP: [Zip],
}

_FILE_TYPE_BY_MAGIC: dict[PipelineType, str] = {
    PipelineType.RAR: ["rar"],
    PipelineType.RTF: ["rtf"],
    PipelineType.PDF: ["pdf"],
    PipelineType.WORD: ["docx"],  # cannot handle doc files.
    PipelineType.XLSX: ["xls", "xlsx"],    
    PipelineType.OFFICE: ["ppt", "pptx", "doc", "fpx"],
    PipelineType.ZIP: ["zip"],
}

def _get_pipeline_type_from_file_type(t: Type) -> PipelineType:
    return next(
        (key for key, value in _FILE_TYPE_MAPPING.items() if type(t) in value),
        PipelineType.UNKNOWN,
    )


def _get_pipeline_type_from_magic_type(file_type: str) -> PipelineType:
    """Return the type of the pipeline using the file type returned from exif meta
    
    Args:
        file_type: The file type from meta
    
    Returns:
        The corresponding meta file type
    """
    matching_pipeline: PipelineType = None
    for pipeline in _FILE_TYPE_BY_MAGIC:
        if file_type.lower() in _FILE_TYPE_BY_MAGIC.get(pipeline):
            matching_pipeline = pipeline
            break
    return matching_pipeline


class FeatureExtractionPipeline(Pipeline):
    """Applies correct pipelines to extract features from files."""

    def process_file(self, path: Path) -> Base:
        print(f"Processing file: {str(path)}")
        pipeline_type = self._get_pipeline_type(path)

        return pipeline_type.value(self._depth, self._max_depth).process_file(path)
    
    def is_valid_pipeline(self, pipeline_type: PipelineType) -> bool:
        """
        """
        if not pipeline_type:
            return False
        if pipeline_type.name == "UNKNOWN":
            return False
        return True

    def _get_pipeline_type(self, path: Path) -> PipelineType:
        """Get appropriate pipeline type for file.

        Args:
            path (Path): path to file.

        Returns:
            PipelineType: suggested type of pipeline to use.
        """
        try:
            type_info = get_file_type(path)
        except Exception:
            print(f"Failed to open file for analysis: {str(path)}")
            return PipelineType.NOT_READABLE
        
        pipeline_type = _get_pipeline_type_from_file_type(type_info.type_filetype)
        if self.is_valid_pipeline(pipeline_type):
            return pipeline_type
        
        pipeline_type = _get_pipeline_type_from_magic_type(type_info.type_magic)
        if pipeline_type:
            return pipeline_type

        return PipelineType.UNKNOWN
